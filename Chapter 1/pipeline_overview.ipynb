{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbfsFfwH/QliQHi8a9EC7W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Pipelines\n","This notebooks gives a short overview about transformer pipelines."],"metadata":{"id":"Dpd4BkHutjfJ"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"eWCvzaaDlWfR","executionInfo":{"status":"ok","timestamp":1753262514263,"user_tz":-330,"elapsed":33667,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}}},"outputs":[],"source":["from transformers import pipeline"]},{"cell_type":"markdown","source":["## Zero Shot Learning\n","In real world projects we need to classify texts that haven't been labelled.\n","But annotating is time consuming and always not be best appraoch.\n","\n","`zero-shot-classification` :\n","- allows us to specify our own labels\n","- classifies text on these specified labels"],"metadata":{"id":"fRUsNRqJuFEw"}},{"cell_type":"code","source":["# zero shot learning pipeline\n","zero_shot = pipeline(\"zero-shot-classification\")\n","\n","# Let's classify text based on our labels\n","zero_shot(\"I am studying how LLMs work. A LLM is a Large Language Model that is trained on vast amount of text data\"\n","          , candidate_labels = [\"computer\" , \"art\" , \"sport\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZ7VulFolacH","executionInfo":{"status":"ok","timestamp":1753262909843,"user_tz":-330,"elapsed":2713,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"4e3634f9-a037-4399-e6d7-f208aa05de05"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["{'sequence': 'I am studying how LLMs work. A LLM is a Large Language Model that is trained on vast amount of text data',\n"," 'labels': ['computer', 'art', 'sport'],\n"," 'scores': [0.8656079769134521, 0.07270870357751846, 0.06168331205844879]}"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Text Generation\n","`text-generation` pipeline generate text based on given prompt.\n","- provide prompt\n","- model will autocomplete the remaining part\n","\n","**Arguments** :\n","- `num_return_sequences` : How many different sequences to generate\n","- `max_length` : total length of the output text"],"metadata":{"id":"MggiIw5ZvNZM"}},{"cell_type":"code","source":["# text generation pipeline\n","text_gen = pipeline(\"text-generation\")\n","\n","# generate text\n","text_gen(\"Tell me about Japan\" , num_return_sequences = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edzwB358mwpR","executionInfo":{"status":"ok","timestamp":1753263350295,"user_tz":-330,"elapsed":39824,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"8dabc19a-151a-4e31-fc6a-5693171023f9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': \"Explain me about Large Language Models in short \\xa0short posts.\\nThis is a really fun post, but I'm going to let you start reading this post and get excited about it.\\nFirst off, I want to say this: I'm not making assumptions about how languages work. I'm not saying that languages don't have some kind of set of rules. I am not saying that your language is a set of rules. I'm just saying that using a set of languages helps me understand some of the concepts that you are seeing in your language.\\nThe problem is, these ideas are very common. I can't teach you this stuff in my language, but I can tell you I do it, and that's what I want you to do.\\nI hope you enjoyed this post. It's a post that I write about writing languages that can be more than just a set of rules. It's a post that I write to let you know that there is a place for you to learn more about the concepts that make your language so special.\\nI hope you enjoyed it, and I hope that this post inspires you to learn more about small languages.\\nThe following languages are examples of languages that I've found to be useful for learning (I will use these as examples):\\nLisp\\nL\"},\n"," {'generated_text': \"Explain me about Large Language Models in short vernacular.\\n\\nTo sum up, here are some examples of languages that are used in this paper:\\n\\nChinese : This is just a single-word sentence that has several components.\\n\\n: This is just a single-word sentence that has several components. Chinese is a single-word sentence that has many components. Turkish: This is just a single sentence that has several components.\\n\\nSo what is this about? It's very interesting to look at, but I'll leave it up to you to get started. First, let's look at some of the features of Chinese language. First, let's get a little background on the language and its underlying structure.\\n\\nChinese ( 名 名 )\\n\\nChinese is a language with a specific set of features. One of the most common features is the number of characters in a word, which is also the same as the number of letters in a word.\\n\\nMany Chinese characters are translated into different ways. For example, Chinese characters in English are translated into Japanese characters. In English, the letters are in various ways, like in the following:\\n\\ne.g. e.g. -e e\\n\\ne.g. -e -e -e -\"}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## Mask Filling\n","Works like fill-in-the-blanks.\n","Guess the word which can be used instead of `<mask>`\n","\n","**Arguments** :\n","- `top_k` : how many possibilities to display"],"metadata":{"id":"09gmXpKgwBdH"}},{"cell_type":"code","source":["# mask filling pipeline\n","mask_filling = pipeline(\"fill-mask\")\n","\n","# This works as fill-in-the-blanks .\n","# Use <mask> to indicate blank space\n","mask_filling(\"Natural Language Processing (NLP) has <mask> the way we interact with technology, making communication more intuitive and efficient.\" , top_k = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-7LE8_gRnvnm","executionInfo":{"status":"ok","timestamp":1753263680022,"user_tz":-330,"elapsed":593,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"d8e6e1ce-2b54-4c49-81a3-ad667d194ad1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.4017307162284851,\n","  'token': 11229,\n","  'token_str': ' transformed',\n","  'sequence': 'Natural Language Processing (NLP) has transformed the way we interact with technology, making communication more intuitive and efficient.'},\n"," {'score': 0.3558560013771057,\n","  'token': 1714,\n","  'token_str': ' changed',\n","  'sequence': 'Natural Language Processing (NLP) has changed the way we interact with technology, making communication more intuitive and efficient.'}]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# NER pipeline\n","ner = pipeline(\"ner\" , grouped_entities = True)\n","\n","# Let's find Named Entities in a sentence\n","ner(\"OpenAI, Inc. is an American artificial intelligence (AI) organization founded in December 2015 and headquartered in San Francisco, California.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmi7n4Hep9uy","executionInfo":{"status":"ok","timestamp":1753265447780,"user_tz":-330,"elapsed":10281,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"53f3ef35-1470-4274-a947-b8ddaa18a1ea"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Device set to use cpu\n","/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:181: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'entity_group': 'ORG',\n","  'score': np.float32(0.9967308),\n","  'word': 'OpenAI, Inc',\n","  'start': 0,\n","  'end': 11},\n"," {'entity_group': 'MISC',\n","  'score': np.float32(0.99758005),\n","  'word': 'American',\n","  'start': 19,\n","  'end': 27},\n"," {'entity_group': 'MISC',\n","  'score': np.float32(0.53491396),\n","  'word': 'AI',\n","  'start': 53,\n","  'end': 55},\n"," {'entity_group': 'LOC',\n","  'score': np.float32(0.9982227),\n","  'word': 'San Francisco',\n","  'start': 116,\n","  'end': 129},\n"," {'entity_group': 'LOC',\n","  'score': np.float32(0.9987657),\n","  'word': 'California',\n","  'start': 131,\n","  'end': 141}]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# question-answering pipeline\n","qa = pipeline(\"question-answering\")\n","\n","# Let's ask a question based on the context\n","# We need to provide question and contex\n","qa(question = \"When was OpenAI founded ?\"\n","   ,context = \"OpenAI, Inc. is an American artificial intelligence (AI) organization founded in December 2015 and headquartered in San Francisco, California.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dlfxjm_0rVb3","executionInfo":{"status":"ok","timestamp":1753265449570,"user_tz":-330,"elapsed":1803,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"116493a2-01f2-4837-cc71-8593e089b0db"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["{'score': 0.9552261233329773,\n"," 'start': 81,\n"," 'end': 94,\n"," 'answer': 'December 2015'}"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["#summarization pipeline\n","summary = pipeline(\"summarization\")\n","\n","# generate summary of passage\n","summary(\"\"\"\n","\n","NLP enables computers and digital devices to recognize, understand and generate text and speech by combining computational linguistics, the rule-based modeling of human language together with statistical modeling, machine learning and deep learning.\n","\n","NLP research has helped enable the era of generative AI, from the communication skills of large language models (LLMs) to the ability of image generation models to understand requests. NLP is already part of everyday life for many, powering search engines, prompting chatbots for customer service with spoken commands, voice-operated GPS systems and question-answering digital assistants on smartphones such as Amazon’s Alexa, Apple’s Siri and Microsoft’s Cortana.\n","\n","NLP also plays a growing role in enterprise solutions that help streamline and automate business operations, increase employee productivity and simplify business processes.\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhuqlCSRr3zf","executionInfo":{"status":"ok","timestamp":1753265462722,"user_tz":-330,"elapsed":13144,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"c66ab5ff-92cb-4063-ab51-d7a642de4488"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'summary_text': ' NLP research has helped enable the era of generative AI, from the communication skills of large language models to the ability of image generation models to understand requests . NLP is already part of everyday life for many, powering search engines, prompting chatbots for customer service with spoken commands .'}]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# translation pipeline\n","translation = pipeline(\"translation_en_to_fr\")\n","\n","translation(\"I am studying how LLMs work. A LLM is a Large Language Model that is trained on vast amount of text data\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHuRiy2MsiR5","executionInfo":{"status":"ok","timestamp":1753265473668,"user_tz":-330,"elapsed":10902,"user":{"displayName":"Atul Deshpande","userId":"08542718426656085499"}},"outputId":"a4b6e704-6e9c-41bd-e4b7-9518896eb5e1"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","Device set to use cpu\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'translation_text': 'Je suis en train d’étudier comment fonctionnent les LLM. Un LLM est un modèle langagier de grande envergure qui est formé sur une vaste quantité de données textuelles.'}]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"5KTylCMLtFd0"},"execution_count":null,"outputs":[]}]}